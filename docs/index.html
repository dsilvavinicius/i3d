<!DOCTYPE html>
<meta charset="utf-8">

<html>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2, h3 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-lg {
    width: 512px;
    border: 1px solid #ddd;
    display: block;
    margin-left: auto;
    margin-right: auto;
}
.screenshot-elg {
    width: 100%;
    border: 1px solid #ddd;
    display: block;
    margin-left: auto;
    margin-right: auto;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0;
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption_justify {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: justify;
    margin-top: 0px;
    margin-bottom: 64px;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 8px;
    margin-bottom: 64px;
}
.caption_inline {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 8px;
    margin-bottom: 0px;
}
.caption_bold {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 0px;
    margin-bottom: 0px;
    font-weight: bold;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;

  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}
</style>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <title>Exploring Differential Geometry in Neural Implicits</title>
    <meta property="og:description" content="Exploring Differential Geometry in Neural Implicits"/>
    <meta property="og:image" itemprop="image" content="https://dsilvavinicius.github.io/differential_geometry_in_neural_implicits/assets/representative.JPEG">
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@dsilvavinicius">
    <meta name="twitter:title" content="Exploring Differential Geometry in Neural Implicits">
    <meta name="twitter:description" content="A new paper which bridges Discrete Differential Geometry in meshes and (Continuous) Differential Geometry in Neural Implicits.">
    <meta name="twitter:image" content="https://dsilvavinicius.github.io/differential_geometry_in_neural_implicits/assets/representative.JPEG">
</head>


<body>
<div class="container">
    <div class="paper-title">
        <h1>Exploring Differential Geometry in Neural Implicits</h1>
    </div>

    <div id="authors">
        <div class="author-row">
            <div class="col-3 text-center"><a href="https://sites.google.com/site/tiagonovellodebrito">Tiago Novello</a><sup>1*</sup></div>
            <div class="col-3 text-center"><a href="https://schardong.github.io">Guilherme Schardong</a><sup>1,3*</sup></div>
            <div class="col-3 text-center"><a href="http://www.inf.puc-rio.br/~lopes">Hélio Lopes</a><sup>2*</sup></div>
        </div>
        <div class="author-row">
            <div class="col-3 text-center"><a href="https://dsilvavinicius.github.io">Vinícius da Silva</a><sup>2*</sup></div>
            <div class="col-3 text-center"><a href="https://www.lschirmer.com/">Luiz Schirmer</a><sup>1,3*</sup></div>
            <div class="col-3 text-center"><a href="https://lvelho.impa.br">Luiz Velho</a><sup>1*</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-3 text-center"><sup>1</sup>IMPA</div>
            <div class="col-3 text-center"><sup>2</sup>PUC-Rio</div>
            <div class="col-3 text-center"><sup>3</sup>University of Coimbra</div>
        </div>

        <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="paper-btn" href="assets/novello2022exploring.pdf">
                    <span class="material-icons"> description </span>
                    Paper
                </a>
                <a class="paper-btn" href="assets/Differential_geometry_of_implicit_functions.pdf">
                    <span class="material-icons"> description </span>
                    Appx
                </a>
                <a class="paper-btn" href="https://youtu.be/ugeR3MVUGng">
                    <span class="material-icons"> videocam </span>
                    Video
                </a>
                <a class="paper-btn" href="https://github.com/dsilvavinicius/differential_geometry_in_neural_implicits/">
                    <span class="material-icons"> code </span>
                    Code
                </a>
            </div>
        </div>
    </div>

    <section id="teaser-videos">
        <!--
        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Coarse
            </p>
        </figure>

        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Neural Implicit Normal Mapping
            </p>
        </figure>

        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Baseline
            </p>
        </figure>
        -->

        <figure style="width: 100%; float: left">
            <img class="screenshot-elg" src="assets/representative.jpg">
        </figure>

        <figure style="width: 100%; float: left">
            <p class="caption_justify">
                Armadillo curvature rendering. An important advantage of using neural implicit functions to represent surfaces is that we can compute their differentiable objects analytically. The image was generated using a transfer function to visualize the gaussian and mean curvatures of the neural surface. This function relates points with high/medium/low curvatures to the red/white/blue colors. Our model enables both normal vectors and mean curvature to be calculated analytically through their formulas using <code>torch.autograd</code>.
            </p>
        </figure>

        <figure style="width: 100%; float: left">
            <video class="centered" width="100%" autoplay muted loop playsinline>
                <source src="assets/teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>

        <figure style="width: 100%; float: left">
            <p class="caption_justify">
                Stanford Bunny, Dragon, Armadillo and Happy Buddha trained with the proposed framework.
            </p>
        </figure>
    </section>

    <section id="news">
        <h2>News</h2>
        <hr>
        <div class="row">
            <div><span class="material-icons"> description </span> [Jan 27th 2022] Page online.</div>
        </div>
        <div class="row">
            <div><span class="material-icons"> description </span> [Set 5th 2022] Accepted for publication on Computer&Graphics.</div>
        </div>
        <div class="row">
            <div><span class="material-icons"> description </span> [Set 5th 2022] Code available online.</div>
        </div>
        <div class="row">
            <div><span class="material-icons"> description </span> [Set 6th 2022] Appendix added.</div>
        </div>
        <div class="row">
            <div><span class="material-icons"> description </span> [TBA] Presentation on SIBGRAPI (2022).</div>
        </div>
    </section>

    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr>
    <p>
      We introduce a neural implicit framework that exploits the differentiable properties of neural networks and the discrete geometry of point-sampled surfaces to approximate them as the level sets of <i>neural implicit functions</i>.<br><br>

      To train a neural implicit function, we propose a loss functional that approximates a signed distance function, and allows terms with high-order derivatives, such as the alignment between the principal directions of curvature, to learn more geometric details.<br><br>
      During training, we consider a non-uniform sampling strategy based on the curvatures of the point-sampled surface to prioritize points with more geometric details. This sampling implies faster learning while preserving geometric~accuracy when compared with previous approaches.<br><br>

      We also use the analytical derivatives of a neural implicit function to estimate the differential measures of the underlying point-sampled surface.
    </p>
    </section>

    <section id="overview"/>
        <h2>Overview</h2>
        <hr>
        <p>
            The main contribution of our work is a global geometric representation in the continuous setting using neural networks as implicit functions. Besides capturing geometric detail, this model is robust for shape analysis and it is efficient since we have its derivatives in closed form.<br>

            Specifically, we propose a loss function that allows the exploration of tools from continuous differential geometry during the training of the neural implicit function. This results in high fidelity when reconstructing geometric features of the surface.<br>

            During the training of the neural implicit function, we use the discrete differential geometry of the dataset (triangle mesh) to sample important regions. This results in robust and fast training, without losing geometric details.<br>

            <!-- Defining the appropriate depth/width of the neural implicit function to represent a given surface remains an open problem. However, if the network has more capacity than necessary, we propose an optimization of its parameters using SVD. This reduces the number of parameters, allowing for efficient inference. When the network cannot represent a given surface, we just increase the dimension of its hidden domains.<br> -->

            <!-- To visualize neural implicit surfaces in real-time, we present an implementation of the (neural) sphere tracing in GPU. We also adopt the above network optimization for efficient memory usage during the sphere tracing.<br> -->
        </p>
    </section>

    <section id="results">
        <h2>Results</h2>
        <hr>

        <div>
            <div class="col-2 text-center">
                <h3>Bunny</h3>
                <hr>

                <figure>
                    <video class="centered" width="100%" autoplay muted loop playsinline>
                        <source src="assets/bunny.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </figure>
            </div>

            <div class="col-2 text-center">
                <h3>Dragon</h3>
                <hr>

                <figure>
                    <video class="centered" width="100%" autoplay muted loop playsinline>
                        <source src="assets/dragon.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </figure>
            </div>
        </div>

        <div>
            <div class="col-2 text-center">
                <h3>Armadillo</h3>
                <hr>

                <figure>
                    <video class="centered" width="100%" autoplay muted loop playsinline>
                        <source src="assets/armadillo.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </figure>
            </div>

            <div class="col-2 text-center">
                <h3>Buddha</h3>
                <hr>

                <figure>
                    <video class="centered" width="100%" autoplay muted loop playsinline>
                        <source src="assets/buddha.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </figure>
            </div>
        </div>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="assets/novello2022exploring.pdf"><img class="screenshot" src="assets/paper-thumbnail.png"></a>
            </div>
            <div style="width: 60%">
                <p><b>Exploring Differential Geometry in Neural Implicits</b></p>
                <p>Tiago Novello, Guilherme Schardong, Luiz Schirmer, Vinícius da Silva, Hélio Lopes and Luiz Velho</p>

                <div><span class="material-icons"> description </span><a href="assets/novello2022exploring.pdf"> Paper preprint (PDF, 10.4 MB)</a></div>
                <div><span class="material-icons"> description </span><a href="https://arxiv.org/abs/2201.09263"> arXiv version</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/novello2022differential.bib"> BibTeX</a></div>
                <div><span class="material-icons"> videocam </span><a href="https://youtu.be/ugeR3MVUGng"> Video</a></div>

                <p>Please send feedback and questions to <a href="https://sites.google.com/site/tiagonovellodebrito">Tiago Novello</a>.</p>
            </div>
        </div>
    </section>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@misc{novello:i3d:2022,
doi = {10.48550/ARXIV.2201.09263},
url = {https://arxiv.org/abs/2201.09263},
author = {Novello, Tiago and Schardong, Guilherme and Schirmer, Luiz and da Silva, Vinicius and Lopes, Helio
and Velho, Luiz},
keywords = {Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences,
FOS: Computer and information sciences},
title = {Exploring Differential Geometry in Neural Implicits},
publisher = {arXiv},
year = {2022},
mon = {jan},
copyright = {Creative Commons Attribution 4.0 International}
}</code></pre>
    </section>

    <section id="acknowledgements">
        <h2>Acknowledgements</h2>
        <hr>
        <div class="row">
            <p>
            We would like to thank
            <a href="https://tovacinni.github.io">Towaki Takikawa</a>,
            <a href="https://joeylitalien.github.io">Joey Litalien</a>,
            <a href="https://kangxue.org/">Kangxue Yin</a>,
            <a href="https://scholar.google.de/citations?user=rFd-DiAAAAAJ">Karsten Kreis</a>,
            <a href="https://research.nvidia.com/person/charles-loop">Charles Loop</a>,
            <a href="http://www.cim.mcgill.ca/~derek/">Derek Nowrouzezahrai</a>,
            <a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a>,
            <a href="https://casual-effects.com/">Morgan McGuire</a> and
            <a href="https://www.cs.toronto.edu/~fidler/">Sanja Fidler</a>
            for licensing the code of the paper <a href="https://nv-tlabs.github.io/nglod/">Neural Geometric Level of Detail:
                Real-time Rendering with Implicit 3D Surfaces</a> and project page under the <a href=https://opensource.org/licenses/MIT>MIT License</a>. This website is based on that page.
            <br/>
            <br/>
            <em>We also thank the <a href="https://graphics.stanford.edu">Stanford Computer Graphics Laboratory</a> for the Bunny, Dragon, Armadillo, and Happy Buddha, acquired through the <a href="http://graphics.stanford.edu/data/3Dscanrep/">Stanford 3D scan repository</a>.
            </p>
        </div>
    </section>
</div>
</body>

</html>
